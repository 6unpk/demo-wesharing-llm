/**
 * LLM Chat Application Template
 *
 * A simple chat application using Cloudflare Workers AI.
 * This template demonstrates how to implement an LLM-powered chat interface with
 * streaming responses using Server-Sent Events (SSE).
 *
 * @license MIT
 */
import { 
  Env, 
  ChatMessage, 
  IntentAnalysisRequest, 
  IntentAnalysisResponseUpdated, 
  IntentType,
  SearchSpaceSuccessResponse,
  SpaceInfo,
  ChatSession,
  SessionMessage,
  SpaceRegistrationState,
  SpaceRegistrationStep
} from "./types";
import type { KVSpaceData } from "./types";
import { GoogleGenerativeAI } from "@google/generative-ai";

// Model ID for Workers AI model
// https://developers.cloudflare.com/workers-ai/models/

// Space registration steps
const SPACE_REGISTRATION_STEPS: SpaceRegistrationStep[] = [
  {
    step: 1,
    field_name: "name",
    description: "ê³µê°„ì˜ ì´ë¦„",
    required: true,
    example: "ì˜ˆ: 'í™ëŒ€ ì¹´í˜', 'ìŠ¤íŠœë””ì˜¤ A'"
  },
  {
    step: 2,
    field_name: "address",
    description: "ê³µê°„ì˜ ì£¼ì†Œ",
    required: true,
    example: "ì˜ˆ: 'ì„œìš¸íŠ¹ë³„ì‹œ ë§ˆí¬êµ¬ í™ëŒ€ë¡œ 123'"
  },
  {
    step: 3,
    field_name: "space_type",
    description: "ê³µê°„ ìœ í˜•",
    required: true,
    example: "ì˜ˆ: 'Indoor', 'Outdoor', 'Semi-Private'"
  },
  {
    step: 4,
    field_name: "max_capacity",
    description: "ìµœëŒ€ ìˆ˜ìš© ì¸ì›",
    required: true,
    example: "ì˜ˆ: 10, 20, 50"
  },
  {
    step: 5,
    field_name: "area_size",
    description: "ë©´ì  (ì œê³±ë¯¸í„°)",
    required: true,
    example: "ì˜ˆ: 30, 50, 100"
  },
  {
    step: 6,
    field_name: "amenities",
    description: "ì‹œì„¤ ë° í¸ì˜ì‹œì„¤",
    required: false,
    example: "ì˜ˆ: 'ì „ê¸°, ì˜ì, í…Œì´ë¸”, ìŒí–¥ì‹œì„¤'"
  },
  {
    step: 7,
    field_name: "fee_policy",
    description: "ì´ìš©ë£Œ ì •ì±…",
    required: true,
    example: "ì˜ˆ: 'ë¬´ë£Œ', 'ì‹œê°„ë‹¹ 10,000ì›', 'ì¼ì¼ 50,000ì›'"
  },
  {
    step: 8,
    field_name: "opening_hours",
    description: "ìš´ì˜ ì‹œê°„",
    required: true,
    example: "ì˜ˆ: 'í‰ì¼ 09:00-18:00, ì£¼ë§ 10:00-17:00'"
  }
];

/**
 * Get chat session from KV
 */
async function getChatSession(sessionId: string, env: Env): Promise<ChatSession | null> {
  try {
    const sessionKey = `chat_session:${sessionId}`;
    const sessionData = await env.KV.get(sessionKey, "json") as ChatSession | null;
    return sessionData;
  } catch (error) {
    console.error("Error getting chat session:", error);
    return null;
  }
}

/**
 * Save chat session to KV
 */
async function saveChatSession(session: ChatSession, env: Env): Promise<void> {
  try {
    const sessionKey = `chat_session:${session.session_id}`;
    await env.KV.put(sessionKey, JSON.stringify(session));
  } catch (error) {
    console.error("Error saving chat session:", error);
  }
}

/**
 * Add message to chat session
 */
async function addMessageToSession(
  sessionId: string, 
  message: SessionMessage, 
  env: Env
): Promise<void> {
  try {
    let session = await getChatSession(sessionId, env);
    
    if (!session) {
      // Create new session
      session = {
        session_id: sessionId,
        messages: [],
        last_updated: Date.now(),
        created_at: Date.now()
      };
    }
    
    // Add message to session
    session.messages.push(message);
    session.last_updated = Date.now();
    
    // Keep only last 20 messages to prevent session from getting too large
    if (session.messages.length > 20) {
      session.messages = session.messages.slice(-20);
    }
    
    await saveChatSession(session, env);
  } catch (error) {
    console.error("Error adding message to session:", error);
  }
}

/**
 * Get conversation context for LLM
 */
async function getConversationContext(sessionId: string, env: Env): Promise<SessionMessage[]> {
  try {
    const session = await getChatSession(sessionId, env);
    if (!session) {
      return [];
    }
    
    // Return last 10 messages for context
    return session.messages.slice(-10);
  } catch (error) {
    console.error("Error getting conversation context:", error);
    return [];
  }
}

/**
 * Get space registration state from KV
 */
async function getSpaceRegistrationState(sessionId: string, env: Env): Promise<SpaceRegistrationState | null> {
  try {
    const stateKey = `space_registration:${sessionId}`;
    const stateData = await env.KV.get(stateKey, "json") as SpaceRegistrationState | null;
    return stateData;
  } catch (error) {
    console.error("Error getting space registration state:", error);
    return null;
  }
}

/**
 * Save space registration state to KV
 */
async function saveSpaceRegistrationState(state: SpaceRegistrationState, env: Env): Promise<void> {
  try {
    const stateKey = `space_registration:${state.session_id}`;
    await env.KV.put(stateKey, JSON.stringify(state));
  } catch (error) {
    console.error("Error saving space registration state:", error);
  }
}

/**
 * Initialize space registration state
 */
async function initializeSpaceRegistration(sessionId: string, env: Env): Promise<SpaceRegistrationState> {
  const state: SpaceRegistrationState = {
    session_id: sessionId,
    step: 1,
    collected_data: {},
    required_fields: SPACE_REGISTRATION_STEPS.map(step => step.field_name),
    last_updated: Date.now()
  };
  
  await saveSpaceRegistrationState(state, env);
  return state;
}

/**
 * Extract structured data from user message using LLM
 */
async function extractSpaceDataFromMessage(
  message: string, 
  currentStep: SpaceRegistrationStep,
  conversationContext: SessionMessage[],
  env: Env
): Promise<{ extracted: any; isValid: boolean; error?: string }> {
  try {
    const contextInfo = conversationContext.length > 0 
      ? `\n\nì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸:\n${conversationContext.map(msg => `${msg.role}: ${msg.content}`).join('\n')}`
      : '';

    const extractionPrompt = `
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ì—ì„œ ê³µê°„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” AIì…ë‹ˆë‹¤.

í˜„ì¬ ìˆ˜ì§‘ ì¤‘ì¸ ì •ë³´: ${currentStep.description}
í•„ë“œëª…: ${currentStep.field_name}
ì˜ˆì‹œ: ${currentStep.example}
í•„ìˆ˜ ì—¬ë¶€: ${currentStep.required ? 'í•„ìˆ˜' : 'ì„ íƒ'}

ì‚¬ìš©ì ë©”ì‹œì§€: "${message}"${contextInfo}

ìœ„ ë©”ì‹œì§€ì—ì„œ ${currentStep.description}ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
{
  "extracted_value": "ì¶”ì¶œëœ ê°’",
  "is_valid": true/false,
  "error_message": "ì˜¤ë¥˜ê°€ ìˆë‹¤ë©´ ì„¤ëª…"
}

ì£¼ì˜ì‚¬í•­:
- ìˆ«ì í•„ë“œ(ì˜ˆ: max_capacity, area_size)ëŠ” ìˆ«ìë¡œ ë³€í™˜
- ë°°ì—´ í•„ë“œ(ì˜ˆ: amenities)ëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ì„ ë°°ì—´ë¡œ ë³€í™˜
- ìš´ì˜ì‹œê°„ì€ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
- ì¶”ì¶œí•  ìˆ˜ ì—†ê±°ë‚˜ ë¶€ì¡±í•œ ì •ë³´ê°€ ìˆìœ¼ë©´ is_validë¥¼ falseë¡œ ì„¤ì •
`;

    const api_token = env.GOOGLE_AI_STUDIO_TOKEN;
    const account_id = "b227edcf71da28cffe319fe486c42e39";
    const gateway_name = "my-gateway";

    const genAI = new GoogleGenerativeAI(api_token);
    const model = genAI.getGenerativeModel(
      { model: "gemini-1.5-flash" },
      {
        baseUrl: `https://gateway.ai.cloudflare.com/v1/${account_id}/${gateway_name}/google-ai-studio`,
      },
    );

    const result = await model.generateContent(extractionPrompt);
    const response = await result.response;
    const responseText = response.text();
    
    try {
      const parsedResult = JSON.parse(responseText);
      return {
        extracted: parsedResult.extracted_value,
        isValid: parsedResult.is_valid,
        error: parsedResult.error_message
      };
    } catch (parseError) {
      return {
        extracted: null,
        isValid: false,
        error: "ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
      };
    }
    
    return {
      extracted: null,
      isValid: false,
      error: "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    };
  } catch (error) {
    console.error("Error extracting space data:", error);
    return {
      extracted: null,
      isValid: false,
      error: "ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    };
  }
}

/**
 * Generate space ID
 */
async function generateSpaceId(env: Env): Promise<string> {
  try {
    // Get all space keys to find the highest number
    const { keys } = await env.KV.list({ prefix: "space-" });
    let maxNumber = 0;
    
    for (const key of keys) {
      const match = key.name.match(/space-(\d+)/);
      if (match) {
        const number = parseInt(match[1]);
        if (number > maxNumber) {
          maxNumber = number;
        }
      }
    }
    
    return `space-${maxNumber + 1}`;
  } catch (error) {
    console.error("Error generating space ID:", error);
    return `space-${Date.now()}`;
  }
}

/**
 * Creates a failure response
 */
function createFailureResponse(errors: Array<{ message: string }>): Response {
  const failureResponse: IntentAnalysisResponseUpdated = {
    status: "FAILURE",
    error: errors,
  };

  return new Response(JSON.stringify(failureResponse), {
    status: 400,
    headers: { "content-type": "application/json" },
  });
}

/**
 * Get all spaces from KV storage (keys starting with 'space')
 */
async function getAllSpacesFromKV(env: Env): Promise<KVSpaceData[]> {
  try {
    console.log("Fetching all spaces from KV");
    
    // List all keys starting with 'space'
    const { keys } = await env.KV.list();
    console.log(`Found ${keys.length} space keys in KV`);
    
    // Fetch all space data
    const spacePromises = keys.map(async (key) => {
      const data = await env.KV.get(key.name, "json");
      return data as KVSpaceData;
    });
    
    const spaces = await Promise.all(spacePromises);
    const validSpaces = spaces.filter((space): space is KVSpaceData => space !== null);
    
    console.log(`Retrieved ${validSpaces.length} valid spaces from KV`);
    return validSpaces;
  } catch (error) {
    console.error("Error fetching spaces from KV:", error);
    return [];
  }
}

/**
 * Filter spaces based on user message
 */
function filterSpacesByMessage(spaces: KVSpaceData[], message: string): KVSpaceData[] {
  console.log(`Filtering ${spaces.length} spaces based on message: "${message}"`);
  
  // Simple keyword-based filtering
  const lowerMessage = message || '';
  
  return spaces.filter(space => {
    // Check address for location match
    if (lowerMessage.includes("ì¸ì²œ") && space.address?.includes("ì¸ì²œ")) return true;
    if (lowerMessage.includes("ì„œìš¸") && space.address?.includes("ì„œìš¸")) return true;
    if (lowerMessage.includes("ë¶€ì‚°") && space.address?.includes("ë¶€ì‚°")) return true;
    
    // Check amenities for equipment match
    if (lowerMessage.includes("ì˜¤ë””ì˜¤") && space.amenities?.some(a => a?.includes("ìŒí–¥") || a?.includes("ì˜¤ë””ì˜¤"))) return true;
    if (lowerMessage.includes("ë§ˆì´í¬") && space.amenities?.some(a => a?.includes("ë§ˆì´í¬"))) return true;
    if (lowerMessage.includes("í”„ë¡œì í„°") && space.amenities?.some(a => a?.includes("í”„ë¡œì í„°"))) return true;
    
    // Check space type
    if (lowerMessage.includes("ì‹¤ë‚´") && space.space_type?.includes("indoor")) return true;
    if (lowerMessage.includes("ì•¼ì™¸") && space.space_type?.includes("outdoor")) return true;
    
    // If no specific filters, return all active spaces
    return false;
  });
}

/**
 * Convert KV space data to API response format
 */
function convertKVSpaceToSpaceInfo(kvSpace: KVSpaceData): SpaceInfo {
  return {
    id: parseInt(kvSpace.space_id?.replace(/\D/g, '') || '0') || 0, // Extract number from space_id
    name: kvSpace.name || '',
    space_type: kvSpace.space_type || '',
    address: kvSpace.address || '',
    coordinate: {
      lat: kvSpace.coordinate?.lat || 0,
      lng: kvSpace.coordinate?.lng || 0
    },
    access_type: kvSpace.access_type || '',
    capacity: kvSpace.max_capacity || 0,
    area_size: kvSpace.area_size || 0,
    amenities: kvSpace.amenities || [],
    accessibility: kvSpace.accessibility || [],
    sensors: kvSpace.sensors || { cctv: false, noise: false },
    access_frequency: "ë³´í†µ", // Default value
    status: kvSpace.status || 'active',
    opening_hours: kvSpace.opening_hours || {
      monday: "closed",
      tuesday: "closed", 
      wednesday: "closed",
      thursday: "closed",
      friday: "closed",
      saturday: "closed",
      sunday: "closed",
      holidays: "closed",
      notes: null
    },
    fee_policy: kvSpace.fee_policy || '',
    booking_policy: kvSpace.booking_policy || {
      cancellation: false,
      modification: false,
      reservation_required: false,
      deposit_required: false
    },
    max_mins_per_use: kvSpace.max_mins_per_use || 120,
    min_mins_per_use: kvSpace.min_mins_per_use || 60,
    characteristics: {
      SOCIO_ECOLOGICAL: Object.values(kvSpace.characteristics || {}).flat(),
      MEANING_HOLDING: Object.values(kvSpace.temporal_pattern || {}).flat(),
      CO_HOLDING: Object.values(kvSpace.outcome_affordance || {}).flat(),
      CARE_INVITING: Object.values(kvSpace.governance_mode || {}).flat(),
      RITUAL_HOLDING: Object.values(kvSpace.norm || {}).flat(),
      QUIET_APPRECIATION: [],
      QUIET_COEXISTENCE: [],
      PERMISSION_FLEXIBLE: [],
      JOY_GENERATIVE: [],
      THRESHOLD_SPACE: []
    },
    temporal_pattern: {
      RESTORATION_BOUND: [],
      DAILY_CYCLE: [],
      RITUAL_INTERVAL: [],
      THRESHOLD_ACTIVATED: [],
      POP_UP_COMPATIBLE: []
    },
    outcome_affordance: {
      TRUST_BUILDING: [],
      MENTAL_HEALTH_SUPPORTING: [],
      RESOURCE_SHARING_ENABLING: [],
      CARBON_REDUCING: [],
      STEWARDSHIP_LEARNING: [],
      DIGITAL_TRACEABLE: [],
      CRISIS_BUFFERING: [],
      INTERGENERATIONAL_BRIDGING: [],
      POLICY_INFORMING: []
    },
    governance_mode: {
      PEER_MODERATED: [],
      ROTATING_CUSTODIANSHIP: [],
      YOUTH_LED: [],
      AI_ASSISTED: []
    },
    norms: {
      FACILITY_PRESERVATION: [],
      ATMOSPHERE_MAINTENANCE: [],
      PRE_APPROVAL: [],
      COLLABORATIVE_FEEDBACK: [],
      SPATIAL_CONSIDERATION: []
    },
    rating: 0
  };
}

export default {
  /**
   * Main request handler for the Worker
   */
  async fetch(
    request: Request,
    env: Env,
    ctx: ExecutionContext,
  ): Promise<Response> {
    const url = new URL(request.url);

    // Handle static assets (frontend) - TEMPORARILY DISABLED
    // if (url.pathname === "/" || (!url.pathname.startsWith("/api/") && !url.pathname.startsWith("/llm/"))) {
    //   return env.ASSETS.fetch(request);
    // }
    
    // Return API server message for root path
    if (url.pathname === "/") {
      return new Response("API Server - Only /llm/analyze-intent endpoint is available", { 
        status: 200,
        headers: { "content-type": "text/plain" }
      });
    }

    // API Routes - CHAT API TEMPORARILY DISABLED
    // if (url.pathname === "/api/chat") {
    //   // Handle POST requests for chat
    //   if (request.method === "POST") {
    //     return handleChatRequest(request, env);
    //   }

    //   // Method not allowed for other request types
    //   return new Response("Method not allowed", { status: 405 });
    // }

    // Intent analysis API route
    if (url.pathname === "/llm/analyze-intent") {
      // Handle POST requests for intent analysis
      if (request.method === "POST") {
        return handleIntentAnalysisRequest(request, env);
      }

      // Method not allowed for other request types
      return new Response("Method not allowed", { status: 405 });
    }

    // Handle 404 for unmatched routes
    return new Response("API Server - Only /llm/analyze-intent endpoint is available", { 
      status: 404,
      headers: { "content-type": "text/plain" }
    });
  },
} satisfies ExportedHandler<Env>;

/**
 * Handles chat API requests - TEMPORARILY DISABLED
 */
// async function handleChatRequest(
//   request: Request,
//   env: Env,
// ): Promise<Response> {
//   try {
//     // Parse JSON request body
//     const { messages = [] } = (await request.json()) as {
//       messages: ChatMessage[];
//     };

//     // Add system prompt if not present
//     if (!messages.some((msg) => msg.role === "system")) {
//       messages.unshift({ role: "system", content: SYSTEM_PROMPT });
//     });

//     const response = await env.AI.run(
//       MODEL_ID,
//       {
//         messages,
//         max_tokens: 1024,
//       },
//       {
//         returnRawResponse: true,
//         // Uncomment to use AI Gateway
//         // gateway: {
//         //   id: "YOUR_GATEWAY_ID", // Replace with your AI Gateway ID
//         //   skipCache: false,      // Set to true to bypass cache
//         //   cacheTtl: 3600,        // Cache time-to-live in seconds
//         // },
//       },
//     );

//     // Return streaming response
//     return response;
//   } catch (error) {
//     console.error("Error processing chat request:", error);
//     return new Response(
//       JSON.stringify({ error: "Failed to process request" }),
//       {
//         status: 500,
//         headers: { "content-type": "application/json" },
//       },
//     );
//   }
// }

/**
 * Handles intent analysis API requests
 */
async function handleIntentAnalysisRequest(
  request: Request,
  env: Env,
): Promise<Response> {
  try {
    // Parse JSON request body
    const requestBody = (await request.json()) as IntentAnalysisRequest;
    
    // Validate request body
    const validationError = validateIntentAnalysisRequest(requestBody);
    if (validationError) {
      return createFailureResponse([{ message: validationError }]);
    }

    // Add user message to session
    const userMessage: SessionMessage = {
      role: "user",
      content: requestBody.message,
      timestamp: Date.now()
    };
    await addMessageToSession(requestBody.session_id, userMessage, env);

    // Get conversation context
    const conversationContext = await getConversationContext(requestBody.session_id, env);

    // Analyze intent using LLM with context
    const intentType = await analyzeIntentWithLLM(requestBody.message, conversationContext, env);
    
    // Handle different intents
    let response: IntentAnalysisResponseUpdated;
    
    if (intentType === "SEARCH_SPACE") {
      const searchResult = await handleSearchSpaceFlow(requestBody.message, requestBody.session_id, conversationContext, env);
      
      // Add assistant response to session
      const assistantMessage: SessionMessage = {
        role: "assistant",
        content: searchResult.llm_response,
        intent_type: intentType,
        timestamp: Date.now(),
        metadata: {
          search_results: searchResult.data
        }
      };
      await addMessageToSession(requestBody.session_id, assistantMessage, env);
      
      response = searchResult;
    } else if (intentType === "ADD_SPACE") {
      const addSpaceResult = await handleAddSpaceFlow(requestBody.message, requestBody.session_id, conversationContext, env);
      
      // Add assistant response to session
      const assistantMessage: SessionMessage = {
        role: "assistant",
        content: addSpaceResult.llm_response,
        intent_type: intentType,
        timestamp: Date.now(),
        metadata: addSpaceResult.is_completed ? {
          space_id: addSpaceResult.space_id
        } : undefined
      };
      await addMessageToSession(requestBody.session_id, assistantMessage, env);
      
      response = addSpaceResult;
    } else {
      // Handle other intents with LLM response
      const llmResponse = await generateIntentResponse(intentType, requestBody.message, conversationContext, env);
      
      // Add assistant response to session
      const assistantMessage: SessionMessage = {
        role: "assistant",
        content: llmResponse,
        intent_type: intentType,
        timestamp: Date.now()
      };
      await addMessageToSession(requestBody.session_id, assistantMessage, env);
      
      response = {
        status: "SUCCESS",
        intent_type: intentType as "ADD_SPACE" | "CREATE_USER_PROFILE",
        llm_response: llmResponse
      };
    }

    return new Response(JSON.stringify(response), {
      status: 200,
      headers: { "content-type": "application/json" },
    });
  } catch (error) {
    console.error("Error processing intent analysis request:", error);
    return createFailureResponse([{ message: "Failed to process intent analysis request" }]);
  }
}

/**
 * Validates intent analysis request body
 */
function validateIntentAnalysisRequest(requestBody: any): string | null {
  if (!requestBody) {
    return "Request body is required";
  }

  if (!requestBody.message || typeof requestBody.message !== "string") {
    return "Message is required and must be a string";
  }

  if (requestBody.message.trim().length === 0) {
    return "Message cannot be empty";
  }

  if (!requestBody.session_id || typeof requestBody.session_id !== "string") {
    return "Session ID is required and must be a string";
  }

  return null;
}

/**
 * Analyzes intent using LLM
 */
async function analyzeIntentWithLLM(message: string, conversationContext: SessionMessage[], env: Env): Promise<IntentType> {
  // Build context from conversation history
  const contextInfo = conversationContext.length > 0 
    ? `\n\nì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸:\n${conversationContext.map(msg => `${msg.role}: ${msg.content}`).join('\n')}`
    : '';

  const intentAnalysisPrompt = `
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ë„ë¥¼ íŒŒì•…í•˜ëŠ” AIì…ë‹ˆë‹¤.
ë‹¤ìŒ 3ê°€ì§€ ì˜ë„ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

1. SEARCH_SPACE: ê³µê°„ì„ ì°¾ê±°ë‚˜ ê²€ìƒ‰í•˜ë ¤ëŠ” ì˜ë„ (ì˜ˆ: "í™ëŒ€ ê·¼ì²˜ ì¹´í˜ ì°¾ì•„ì¤˜", "4ëª…ì´ì„œ ê°ˆ ìˆ˜ ìˆëŠ” ì‹ë‹¹")
2. ADD_SPACE: ìƒˆë¡œìš´ ê³µê°„ì„ ë“±ë¡í•˜ê±°ë‚˜ ì¶”ê°€í•˜ë ¤ëŠ” ì˜ë„ (ì˜ˆ: "ìš°ë¦¬ ì¹´í˜ ë“±ë¡í•˜ê³  ì‹¶ì–´", "ìƒˆë¡œìš´ ì¥ì†Œ ì¶”ê°€")  
3. CREATE_USER_PROFILE: ì‚¬ìš©ì í”„ë¡œí•„ì„ ìƒì„±í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ë ¤ëŠ” ì˜ë„ (ì˜ˆ: "í”„ë¡œí•„ ë§Œë“¤ê¸°", "ë‚´ ì •ë³´ ìˆ˜ì •")

í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€: "${message}"${contextInfo}

ìœ„ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ SEARCH_SPACE, ADD_SPACE, CREATE_USER_PROFILE ì¤‘ í•˜ë‚˜ë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
`;

  const messages: ChatMessage[] = [
    {
      role: "system",
      content: "ë‹¹ì‹ ì€ ì˜ë„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë©”ì‹œì§€ë¥¼ ì •í™•íˆ ë¶„ë¥˜í•˜ì—¬ ì‘ë‹µí•´ì£¼ì„¸ìš”.",
    },
    {
      role: "user", 
      content: intentAnalysisPrompt,
    },
  ];

  try {
    const api_token = env.GOOGLE_AI_STUDIO_TOKEN;
    const account_id = "b227edcf71da28cffe319fe486c42e39";
    const gateway_name = "my-gateway";

    const genAI = new GoogleGenerativeAI(api_token);
    const model = genAI.getGenerativeModel(
      { model: "gemini-1.5-flash" },
      {
        baseUrl: `https://gateway.ai.cloudflare.com/v1/${account_id}/${gateway_name}/google-ai-studio`,
      },
    );

    const result = await model.generateContent(intentAnalysisPrompt);
    const response = await result.response;
    const intentResult = response.text().trim().toUpperCase();

    // Validate and return intent type
    if (intentResult.includes("SEARCH_SPACE")) {
      return "SEARCH_SPACE";
    } else if (intentResult.includes("ADD_SPACE")) {
      return "ADD_SPACE";
    } else if (intentResult.includes("CREATE_USER_PROFILE")) {
      return "CREATE_USER_PROFILE";
    } else {
      // Default to SEARCH_SPACE if classification is unclear
      console.warn(`Unclear intent classification: ${intentResult}, defaulting to SEARCH_SPACE`);
      return "SEARCH_SPACE";
    }
  } catch (error) {
    console.error("Error in LLM intent analysis:", error);
    // Default to SEARCH_SPACE on error
    return "SEARCH_SPACE";
  }
}

/**
 * Handles ADD_SPACE flow with step-by-step data collection
 */
async function handleAddSpaceFlow(
  message: string,
  sessionId: string,
  conversationContext: SessionMessage[],
  env: Env
): Promise<{ status: "SUCCESS"; intent_type: "ADD_SPACE"; llm_response: string; is_completed?: boolean; space_id?: string }> {
  try {
    console.log("Starting ADD_SPACE flow");

    // Get or initialize registration state
    let state = await getSpaceRegistrationState(sessionId, env);
    if (!state) {
      state = await initializeSpaceRegistration(sessionId, env);
    }

    const currentStep = SPACE_REGISTRATION_STEPS.find(step => step.step === state.step);
    if (!currentStep) {
      return {
        status: "SUCCESS",
        intent_type: "ADD_SPACE",
        llm_response: "ê³µê°„ ë“±ë¡ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”."
      };
    }

    // Extract data from user message
    const extractionResult = await extractSpaceDataFromMessage(message, currentStep, conversationContext, env);

    if (extractionResult.isValid && extractionResult.extracted !== null) {
      // Save extracted data
      state.collected_data[currentStep.field_name as keyof KVSpaceData] = extractionResult.extracted;
      state.last_updated = Date.now();

      // Move to next step
      state.step++;

      // Check if all required fields are completed
      const isCompleted = state.step > SPACE_REGISTRATION_STEPS.length;
      
      if (isCompleted) {
        // Save the complete space data to KV
        const spaceId = await generateSpaceId(env);
        const completeSpaceData: KVSpaceData = {
          space_id: spaceId,
          name: state.collected_data.name || "",
          space_type: state.collected_data.space_type || "",
          address: state.collected_data.address || "",
          coordinate: state.collected_data.coordinate || { lat: 0, lng: 0 },
          access_type: "open",
          min_capacity: null,
          max_capacity: state.collected_data.max_capacity || 0,
          area_size: state.collected_data.area_size || 0,
          sensors: { noise: false, cctv: false },
          opening_hours: state.collected_data.opening_hours || {
            monday: "closed",
            tuesday: "closed",
            wednesday: "closed",
            thursday: "closed",
            friday: "closed",
            saturday: "closed",
            sunday: "closed",
            holidays: "closed",
            notes: null
          },
          booking_policy: {
            cancellation: false,
            modification: true,
            reservation_required: false,
            deposit_required: false
          },
          min_mins_per_use: null,
          max_mins_per_use: null,
          fee_policy: state.collected_data.fee_policy || "",
          status: "active",
          last_updated: new Date().toISOString(),
          amenities: state.collected_data.amenities || [],
          accessibility: [],
          memory_narrative: "",
          characteristics: {},
          temporal_pattern: {},
          outcome_affordance: {},
          governance_mode: {},
          norm: {},
          owner_entity: "user"
        };

        await env.KV.put(spaceId, JSON.stringify(completeSpaceData));

        // Clear registration state
        await env.KV.delete(`space_registration:${sessionId}`);

        return {
          status: "SUCCESS",
          intent_type: "ADD_SPACE",
          llm_response: `ì¶•í•˜í•©ë‹ˆë‹¤! ê³µê°„ ë“±ë¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ğŸ‰\n\në“±ë¡ëœ ê³µê°„ ì •ë³´:\n- ì´ë¦„: ${completeSpaceData.name}\n- ì£¼ì†Œ: ${completeSpaceData.address}\n- ìœ í˜•: ${completeSpaceData.space_type}\n- ìˆ˜ìš© ì¸ì›: ${completeSpaceData.max_capacity}ëª…\n- ë©´ì : ${completeSpaceData.area_size}ã¡\n- ì´ìš©ë£Œ: ${completeSpaceData.fee_policy}\n\nê³µê°„ ID: ${spaceId}\n\nì´ì œ ë‹¤ë¥¸ ì‚¬ìš©ìë“¤ì´ ì´ ê³µê°„ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ë¡œ ìˆ˜ì •í•˜ê³  ì‹¶ì€ ì •ë³´ê°€ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”!`,
          is_completed: true,
          space_id: spaceId
        };
      } else {
        // Continue to next step
        await saveSpaceRegistrationState(state, env);
        
        const nextStep = SPACE_REGISTRATION_STEPS.find(step => step.step === state.step);
        if (nextStep) {
          return {
            status: "SUCCESS",
            intent_type: "ADD_SPACE",
            llm_response: `ì¢‹ìŠµë‹ˆë‹¤! ${currentStep.description}ì´(ê°€) ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në‹¤ìŒìœ¼ë¡œ ${nextStep.description}ì„(ë¥¼) ì•Œë ¤ì£¼ì„¸ìš”.\n${nextStep.example}`
          };
        }
      }
    } else {
      // Invalid data, ask for clarification
      await saveSpaceRegistrationState(state, env);
      
      return {
        status: "SUCCESS",
        intent_type: "ADD_SPACE",
        llm_response: `ì£„ì†¡í•©ë‹ˆë‹¤. ${currentStep.description}ì„(ë¥¼) ì •í™•íˆ íŒŒì•…í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n\n${currentStep.example}\n\në‹¤ì‹œ í•œ ë²ˆ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?`
      };
    }

    return {
      status: "SUCCESS",
      intent_type: "ADD_SPACE",
      llm_response: "ê³µê°„ ë“±ë¡ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”."
    };
  } catch (error) {
    console.error("Error in handleAddSpaceFlow:", error);
    return {
      status: "SUCCESS",
      intent_type: "ADD_SPACE",
      llm_response: "ê³µê°„ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    };
  }
}

/**
 * Handles SEARCH_SPACE flow with Cloudflare KV
 */
async function handleSearchSpaceFlow(
  message: string,
  sessionId: string,
  conversationContext: SessionMessage[],
  env: Env
): Promise<SearchSpaceSuccessResponse> {
  try {
    console.log("Starting KV-based space search flow");

    // Get all space data from KV
    const spaceData = await getAllSpacesFromKV(env);
    
    // Filter spaces based on user message (basic filtering)
    const filteredSpaces = filterSpacesByMessage(spaceData, message);
    
    console.log(`Found ${filteredSpaces.length} spaces matching criteria`);

    // Convert KV space data to API response format
    const responseSpaces = filteredSpaces.map(convertKVSpaceToSpaceInfo);
    
    // Generate LLM response based on search results
                    const toolResults: Omit<SearchSpaceSuccessResponse, 'llm_response' | 'search_context'> = {
                  status: "SUCCESS",
                  intent_type: "SEARCH_SPACE",
                  data: responseSpaces,
                  total_count: responseSpaces.length
                };
    
    const llmResponse = await generateSearchResultResponse(message, toolResults, conversationContext, env);
    
    // Add LLM response to the result
                    return {
                  status: "SUCCESS",
                  intent_type: "SEARCH_SPACE",
                  data: toolResults.data,
                  total_count: toolResults.total_count,
                  llm_response: llmResponse
                };
  } catch (error) {
    console.error("Error in handleSearchSpaceFlow:", error);
    
    // Return empty result on error
    return {
      status: "SUCCESS",
      intent_type: "SEARCH_SPACE",
      data: [],
      total_count: 0,
      search_context: {
        filters_used: {},
        result_count: 0,
        search_mode: "ERROR",
        excluded_spaces: []
      },
      llm_response: "ì£„ì†¡í•©ë‹ˆë‹¤. ê³µê°„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    };
  }
}


/**
 * Generate LLM response for search results
 */
async function generateSearchResultResponse(
  originalMessage: string,
  searchResult: Omit<SearchSpaceSuccessResponse, 'llm_response' | 'search_context'>,
  conversationContext: SessionMessage[],
  env: Env
): Promise<string> {
  try {
    // Build context from conversation history
    const contextInfo = conversationContext.length > 0 
      ? `\n\nì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸:\n${conversationContext.map(msg => `${msg.role}: ${msg.content}`).join('\n')}`
      : '';

    let responsePrompt = "";
    
    if (searchResult.data.length > 0) {
      const spaces = searchResult.data.map(space => 
        `- ${space.name} (${space.address}): ${space.amenities.join(', ')} ì´ìš© ê°€ëŠ¥`
      ).join('\n');
      
      responsePrompt = `ì‚¬ìš©ì ìš”ì²­: "${originalMessage}"

ê²€ìƒ‰ ê²°ê³¼ ${searchResult.total_count}ê°œì˜ ê³µê°„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:
${spaces}${contextInfo}

ìœ„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”. 
ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•˜ì—¬ ì—°ì†ì ì¸ ëŒ€í™”ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ í•´ì£¼ì„¸ìš”.
ê³µê°„ì˜ íŠ¹ì§•ê³¼ ì´ìš© ë°©ë²•ì„ ê°„ë‹¨íˆ ì„¤ëª…í•˜ê³ , ì¶”ê°€ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ë¼ê³  ì•ˆë‚´í•´ì£¼ì„¸ìš”.`;
    } else {
      responsePrompt = `ì‚¬ìš©ì ìš”ì²­: "${originalMessage}"

ê²€ìƒ‰ ê²°ê³¼ ì¡°ê±´ì— ë§ëŠ” ê³µê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.${contextInfo}

ì‚¬ìš©ìì—ê²Œ ì£„ì†¡í•˜ë‹¤ëŠ” ë§ê³¼ í•¨ê»˜ ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•´ë³´ê±°ë‚˜, 
ë” êµ¬ì²´ì ì¸ ìš”êµ¬ì‚¬í•­ì„ ì•Œë ¤ë‹¬ë¼ê³  ì¹œê·¼í•˜ê²Œ ìš”ì²­í•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•˜ì—¬ ì—°ì†ì ì¸ ëŒ€í™”ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ í•´ì£¼ì„¸ìš”.`;
    }
    
    const api_token = env.GOOGLE_AI_STUDIO_TOKEN;
    const account_id = "b227edcf71da28cffe319fe486c42e39";
    const gateway_name = "my-gateway";

    const genAI = new GoogleGenerativeAI(api_token);
    const model = genAI.getGenerativeModel(
      { model: "gemini-1.5-flash" },
      {
        baseUrl: `https://gateway.ai.cloudflare.com/v1/${account_id}/${gateway_name}/google-ai-studio`,
      },
    );

    const result = await model.generateContent(responsePrompt);
    const response = await result.response;
    return response.text();
  } catch (error) {
    console.error("Error generating search response:", error);
    
    if (searchResult.data.length > 0) {
      return `${searchResult.total_count}ê°œì˜ ê³µê°„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤! ì²« ë²ˆì§¸ ì¶”ì²œ ê³µê°„ì€ "${searchResult.data[0].name}"ì…ë‹ˆë‹¤. ë” ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”.`;
    } else {
      return "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ì¡°ê±´ì— ë§ëŠ” ê³µê°„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§€ì—­ì´ë‚˜ ì¡°ê±´ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•´ë³´ì‹œê² ì–´ìš”?";
    }
  }
}

/**
 * Generate LLM response for other intents
 */
async function generateIntentResponse(
  intentType: IntentType,
  message: string,
  conversationContext: SessionMessage[],
  env: Env
): Promise<string> {
  try {
    // Build context from conversation history
    const contextInfo = conversationContext.length > 0 
      ? `\n\nì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸:\n${conversationContext.map(msg => `${msg.role}: ${msg.content}`).join('\n')}`
      : '';

    let systemPrompt = "";
    let responsePrompt = "";

    switch (intentType) {
      case "ADD_SPACE":
        systemPrompt = "ë‹¹ì‹ ì€ ê³µê°„ ë“±ë¡ì„ ë„ì™€ì£¼ëŠ” ì¹œê·¼í•œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.";
        responsePrompt = `ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ ê³µê°„ì„ ë“±ë¡í•˜ê³  ì‹¶ì–´í•©ë‹ˆë‹¤: "${message}"${contextInfo}

ê³µê°„ ë“±ë¡ ì ˆì°¨ë¥¼ ì•ˆë‚´í•˜ê³ , í•„ìš”í•œ ì •ë³´(ê³µê°„ëª…, ì£¼ì†Œ, ì‹œì„¤, ì—°ë½ì²˜ ë“±)ë¥¼ 
ë‹¨ê³„ë³„ë¡œ ì¹œê·¼í•˜ê²Œ ìš”ì²­í•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•˜ì—¬ ì—°ì†ì ì¸ ëŒ€í™”ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ í•´ì£¼ì„¸ìš”.`;
        break;
        
      case "CREATE_USER_PROFILE":
        systemPrompt = "ë‹¹ì‹ ì€ ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±ì„ ë„ì™€ì£¼ëŠ” ì¹œê·¼í•œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.";
        responsePrompt = `ì‚¬ìš©ìê°€ í”„ë¡œí•„ì„ ë§Œë“¤ê³  ì‹¶ì–´í•©ë‹ˆë‹¤: "${message}"${contextInfo}

í”„ë¡œí•„ ìƒì„± ê³¼ì •ì„ ì•ˆë‚´í•˜ê³ , í•„ìš”í•œ ì •ë³´(ì´ë¦„, ê´€ì‹¬ì‚¬, ì„ í˜¸í•˜ëŠ” ê³µê°„ íƒ€ì… ë“±)ë¥¼ 
ë‹¨ê³„ë³„ë¡œ ì¹œê·¼í•˜ê²Œ ìš”ì²­í•˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•˜ì—¬ ì—°ì†ì ì¸ ëŒ€í™”ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ í•´ì£¼ì„¸ìš”.`;
        break;
        
      default:
        return "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?";
    }

    const api_token = env.GOOGLE_AI_STUDIO_TOKEN;
    const account_id = "b227edcf71da28cffe319fe486c42e39";
    const gateway_name = "my-gateway";

    const genAI = new GoogleGenerativeAI(api_token);
    const model = genAI.getGenerativeModel(
      { model: "gemini-1.5-flash" },
      {
        baseUrl: `https://gateway.ai.cloudflare.com/v1/${account_id}/${gateway_name}/google-ai-studio`,
      },
    );

    const fullPrompt = systemPrompt ? `${systemPrompt}\n\n${responsePrompt}` : responsePrompt;
    const result = await model.generateContent(fullPrompt);
    const response = await result.response;
    return response.text();
  } catch (error) {
    console.error("Error generating intent response:", error);
    
    switch (intentType) {
      case "ADD_SPACE":
        return "ìƒˆë¡œìš´ ê³µê°„ì„ ë“±ë¡í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ê³µê°„ ë“±ë¡ì„ ìœ„í•´ ëª‡ ê°€ì§€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ê³µê°„ì˜ ì´ë¦„ê³¼ ì£¼ì†Œë¶€í„° ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?";
      case "CREATE_USER_PROFILE":
        return "í”„ë¡œí•„ ìƒì„±ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ë¨¼ì € ì‚¬ìš©í•˜ì‹¤ ì´ë¦„ì„ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?";
      default:
        return "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?";
    }
  }
}

